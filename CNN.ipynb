{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce55ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import wfdb\n",
    "import ast\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dropout,Dense,TimeDistributed,Conv1D,MaxPooling1D,Flatten,LSTM,ConvLSTM2D,Conv2D,MaxPooling2D,BatchNormalization,GlobalAveragePooling1D,GlobalMaxPooling1D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53631e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05dd5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================loading data================\n",
      "原数据集训练样本数：19603，去除空值后样本数：10436\n",
      "原数据集测试样本数：2198，去除空值后样本数：1168\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=data.getdata01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd2ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 1, 15, 64\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bf9fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a770d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7829a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define model\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, padding='same',activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, padding='same',strides=1,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, padding='same',strides=1,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "\n",
    "\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.03), metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da87645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 21:47:51.077880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /public/software//compiler/intel/intel-compiler-2017.5.239/compiler/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/mkl/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/tbb/lib/intel64:/usr/local/cuda-10.2/lib64\n",
      "2022-09-30 21:47:51.078009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /public/software//compiler/intel/intel-compiler-2017.5.239/compiler/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/mkl/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/tbb/lib/intel64:/usr/local/cuda-10.2/lib64\n",
      "2022-09-30 21:47:51.078063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /public/software//compiler/intel/intel-compiler-2017.5.239/compiler/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/mkl/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/tbb/lib/intel64:/usr/local/cuda-10.2/lib64\n",
      "2022-09-30 21:47:51.081637: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /public/software//compiler/intel/intel-compiler-2017.5.239/compiler/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/mkl/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/tbb/lib/intel64:/usr/local/cuda-10.2/lib64\n",
      "2022-09-30 21:47:51.081709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /public/software//compiler/intel/intel-compiler-2017.5.239/compiler/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/mkl/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/tbb/lib/intel64:/usr/local/cuda-10.2/lib64\n",
      "2022-09-30 21:47:51.081758: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /public/software//compiler/intel/intel-compiler-2017.5.239/compiler/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/mkl/lib/intel64:/public/software//compiler/intel/intel-compiler-2017.5.239/tbb/lib/intel64:/usr/local/cuda-10.2/lib64\n",
      "2022-09-30 21:47:51.081773: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-30 21:47:51.082302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        tf.keras.layers.Conv1D(filters=128, kernel_size=20, strides=3, padding='same',activation=tf.nn.relu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool1D(pool_size=2, strides=3),\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=7, strides=1, padding='same', activation=tf.nn.relu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool1D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=10, strides=1, padding='same', activation=tf.nn.relu),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(pool_size=2, strides=2), \n",
    "        tf.keras.layers.Flatten(),\n",
    "    ]\n",
    ")\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.03), metrics=['accuracy'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1b8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape=X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d43d5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 334, 128)          30848     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 334, 128)         512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 111, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 111, 32)           28704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 111, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 55, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 55, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 27, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 864)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               86500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 157,166\n",
      "Trainable params: 156,846\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=input_shape),\n",
    "#         layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation=\"softmax\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c26502e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1500\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.003), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27176834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "74/74 [==============================] - 9s 99ms/step - loss: 0.4417 - accuracy: 0.8291 - val_loss: 0.5122 - val_accuracy: 0.7021\n",
      "Epoch 2/1500\n",
      "74/74 [==============================] - 7s 100ms/step - loss: 0.2453 - accuracy: 0.9034 - val_loss: 0.6676 - val_accuracy: 0.6015\n",
      "Epoch 3/1500\n",
      "74/74 [==============================] - 7s 96ms/step - loss: 0.2212 - accuracy: 0.9121 - val_loss: 0.3366 - val_accuracy: 0.8477\n",
      "Epoch 4/1500\n",
      "74/74 [==============================] - 7s 90ms/step - loss: 0.2045 - accuracy: 0.9179 - val_loss: 0.3244 - val_accuracy: 0.8659\n",
      "Epoch 5/1500\n",
      "74/74 [==============================] - 7s 93ms/step - loss: 0.1896 - accuracy: 0.9232 - val_loss: 0.3303 - val_accuracy: 0.8640\n",
      "Epoch 6/1500\n",
      "74/74 [==============================] - 7s 93ms/step - loss: 0.1663 - accuracy: 0.9321 - val_loss: 0.3217 - val_accuracy: 0.8812\n",
      "Epoch 7/1500\n",
      "74/74 [==============================] - 5s 63ms/step - loss: 0.1589 - accuracy: 0.9340 - val_loss: 0.3508 - val_accuracy: 0.8860\n",
      "Epoch 8/1500\n",
      "74/74 [==============================] - 4s 55ms/step - loss: 0.1420 - accuracy: 0.9412 - val_loss: 0.3556 - val_accuracy: 0.8726\n",
      "Epoch 9/1500\n",
      "74/74 [==============================] - 4s 55ms/step - loss: 0.1194 - accuracy: 0.9520 - val_loss: 0.4043 - val_accuracy: 0.8755\n",
      "Epoch 10/1500\n",
      "74/74 [==============================] - 5s 64ms/step - loss: 0.0919 - accuracy: 0.9648 - val_loss: 0.4303 - val_accuracy: 0.8669\n",
      "Epoch 11/1500\n",
      "74/74 [==============================] - 7s 89ms/step - loss: 0.0873 - accuracy: 0.9651 - val_loss: 0.3519 - val_accuracy: 0.8784\n",
      "Epoch 12/1500\n",
      "74/74 [==============================] - 5s 71ms/step - loss: 0.0693 - accuracy: 0.9733 - val_loss: 0.4077 - val_accuracy: 0.8755\n",
      "Epoch 13/1500\n",
      "74/74 [==============================] - 7s 96ms/step - loss: 0.0569 - accuracy: 0.9783 - val_loss: 0.4572 - val_accuracy: 0.8784\n",
      "Epoch 14/1500\n",
      "74/74 [==============================] - 7s 94ms/step - loss: 0.0452 - accuracy: 0.9825 - val_loss: 0.5733 - val_accuracy: 0.8649\n",
      "Epoch 15/1500\n",
      "74/74 [==============================] - 7s 92ms/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.5397 - val_accuracy: 0.8736\n",
      "Epoch 16/1500\n",
      "74/74 [==============================] - 7s 97ms/step - loss: 0.0508 - accuracy: 0.9821 - val_loss: 0.6022 - val_accuracy: 0.8592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe571ecd5e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be250ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51af44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 8ms/step\n",
      "准确率：  0.8827054794520548\n",
      "混淆矩阵：\n",
      "[[130 126]\n",
      " [ 11 901]]\n",
      "precision_score:  0.8773125608568647\n",
      "recall:  0.9879385964912281\n",
      "f1 score:  0.9293450232078391\n"
     ]
    }
   ],
   "source": [
    "actual = np.array(y_test).argmax(axis=1)     #真实的类别标签（将one-hot)标签逆向\n",
    "predict_x=model.predict(X_test) #预测标签\n",
    "predicted=np.argmax(np.array(predict_x),axis=1)#one-hot编码逆向\n",
    "\n",
    "# 计算总的精度\n",
    "acc = accuracy_score(actual, predicted)\n",
    "print(\"准确率： \",acc)\n",
    "# 计算混淆矩阵\n",
    "print(\"混淆矩阵：\")\n",
    "print(confusion_matrix(actual, predicted))\n",
    "#计算 precision_score\n",
    "print(\"precision_score:\",end=\"  \")\n",
    "print(precision_score(actual, predicted, average=\"binary\", pos_label=1)) # pos_label设置为1，代表标签为1的样本是正例，标签为2的样本是负例。\n",
    "#\trecall\n",
    "print(\"recall: \",end=\" \")\n",
    "print(recall_score(actual, predicted, average=\"binary\", pos_label=1))\n",
    "#\tF1\n",
    "print(\"f1 score: \",end=\" \")\n",
    "print(f1_score(actual, predicted, average=\"binary\", pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f7464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3206626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcfba83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc098f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650985f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
